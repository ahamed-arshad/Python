{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e983a37c",
   "metadata": {},
   "source": [
    "# Sentimental Analysis of 1.6 M Data using VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fbb41",
   "metadata": {},
   "source": [
    "### Introduction to VADER\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool designed for analyzing sentiment in text data. Developed by C.J. Hutto and Eric Gilbert, VADER is widely used for sentiment analysis tasks due to its simplicity and effectiveness, especially in social media contexts. It features a pre-trained lexicon containing thousands of words with associated sentiment scores, along with rules and heuristics to handle linguistic nuances and context-specific sentiments. VADER is \"valence aware,\" meaning it considers the valence of words in context to accurately interpret sentiments expressed in text. It assigns sentiment intensity scores, including positive, negative, and neutral scores, as well as a compound score representing the overall sentiment polarity of the text. VADER finds applications in social media analysis, customer feedback analysis, and brand monitoring, providing a robust and efficient solution for sentiment analysis tasks in both research and industry settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750ffa3",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "The primary objective of this project is to assess the performance of the VADER sentiment analysis tool when applied to both cleaned and uncleaned text data. Additionally, we aim to establish a baseline score for sentiment analysis using VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf6e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\MILAN\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce1563ff",
   "metadata": {},
   "source": [
    "The SentimentIntensityAnalyzer class from NLTK's VADER module is used to perform sentiment analysis on text data. It analyzes the sentiment of the provided text and returns a dictionary of sentiment scores, including positive, negative, neutral, and compound scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0ffe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'compound': 0.6369}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"I love this product. It is amaing.\"\n",
    "\n",
    "sentiment_scores = sia.polarity_scores(text)\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f24d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "compound_score = sentiment_scores['compound']\n",
    "\n",
    "if compound_score >= 0.05:\n",
    "    print(\"Positive\")\n",
    "elif compound_score <= -0.05:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c795ee",
   "metadata": {},
   "source": [
    "### Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd0506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(\"/path/to/nltk_data\")\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe1123",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e005de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"C:/Users/MILAN/Downloads/training.1600000.processed.noemoticon.csv\",  encoding = \"ISO-8859-1\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c94dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                               text_  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns = [\"target\", \"ids\", \"Date\", \"flag\", \"user\", \"text_\"]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04433776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1599999 non-null  int64 \n",
      " 1   ids     1599999 non-null  int64 \n",
      " 2   Date    1599999 non-null  object\n",
      " 3   flag    1599999 non-null  object\n",
      " 4   user    1599999 non-null  object\n",
      " 5   text_   1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df47380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>774362</td>\n",
       "      <td>1</td>\n",
       "      <td>659775</td>\n",
       "      <td>1581465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Mon Jun 15 12:53:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lost_dog</td>\n",
       "      <td>isPlayer Has Died! Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>1599999</td>\n",
       "      <td>549</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date      flag      user  \\\n",
       "count                        1599999   1599999   1599999   \n",
       "unique                        774362         1    659775   \n",
       "top     Mon Jun 15 12:53:14 PDT 2009  NO_QUERY  lost_dog   \n",
       "freq                              20   1599999       549   \n",
       "\n",
       "                            text_  \n",
       "count                     1599999  \n",
       "unique                    1581465  \n",
       "top     isPlayer Has Died! Sorry   \n",
       "freq                          210  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e0d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685418ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['target'] = tweets['target'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e9bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598314"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['ids'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79648fa0",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e5de43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>@Nkluvr4eva My poor little dumpling  In Holmde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date            user  \\\n",
       "0       0  2200003313  Tue Jun 16 18:18:13 PDT 2009   DEWGetMeTho77   \n",
       "1       0  1467998601  Mon Apr 06 23:11:18 PDT 2009         Young_J   \n",
       "2       0  2300049112  Tue Jun 23 13:40:12 PDT 2009   dougnawoschik   \n",
       "3       0  1993474319  Mon Jun 01 10:26:09 PDT 2009        thireven   \n",
       "4       0  2256551006  Sat Jun 20 12:56:51 PDT 2009  taracollins086   \n",
       "\n",
       "                                               text_  \n",
       "0  @Nkluvr4eva My poor little dumpling  In Holmde...  \n",
       "1  I'm off too bed. I gotta wake up hella early t...  \n",
       "2  I havent been able to listen to it yet  My spe...  \n",
       "3  now remembers why solving a relatively big equ...  \n",
       "4                           Ate too much, feel sick   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.sample(n=100000, random_state=42)\n",
    "tweets = tweets.drop_duplicates(subset=['ids'])\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "column_to_delete = ['flag']\n",
    "tweets = tweets.drop(column_to_delete, axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6332f",
   "metadata": {},
   "source": [
    "Removing usernames from text: Iterating over each row in the 'text' column and checking if the text starts with a '@' symbol, indicating a mention. If a mention is found, we are removing the mention by finding the index of the first space character after the '@' symbol and retains the text following that space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676a43ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date            user  \\\n",
       "0       0  2200003313  Tue Jun 16 18:18:13 PDT 2009   DEWGetMeTho77   \n",
       "1       0  1467998601  Mon Apr 06 23:11:18 PDT 2009         Young_J   \n",
       "2       0  2300049112  Tue Jun 23 13:40:12 PDT 2009   dougnawoschik   \n",
       "3       0  1993474319  Mon Jun 01 10:26:09 PDT 2009        thireven   \n",
       "4       0  2256551006  Sat Jun 20 12:56:51 PDT 2009  taracollins086   \n",
       "\n",
       "                                                text  \n",
       "0  My poor little dumpling  In Holmdel vids he wa...  \n",
       "1  I'm off too bed. I gotta wake up hella early t...  \n",
       "2  I havent been able to listen to it yet  My spe...  \n",
       "3  now remembers why solving a relatively big equ...  \n",
       "4                           Ate too much, feel sick   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'] = tweets['text_']\n",
    "\n",
    "for i in range(len(tweets['text'])):\n",
    "    str_val = tweets['text'].iloc[i]\n",
    "    if str_val.startswith(\"@\"):\n",
    "        first_idx = str_val.index(\" \") + 1\n",
    "        tweets.loc[i, 'text'] = str_val[first_idx:]\n",
    "\n",
    "tweets.drop(columns=['text_'], inplace=True)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2e7c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tweets.Date:\n",
    "    l = len(tweets.Date.iloc[0])\n",
    "    if ((len(i)!=l) and (i[3]!=\" \") and (i[7]!=\" \") and (i[0]!=\" \") and (i[19]!=\" \") and (i[23]!=\" \")):\n",
    "        print(i, \"inconsistent\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43f8e3",
   "metadata": {},
   "source": [
    "Handling Date column: Extracting date components from the 'Date' column, combining them into a datetime format, and dropping the original date components columns, resulting in a DataFrame with the desired datetime information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41440c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16  \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06  \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23  \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01  \n",
       "4                           Ate too much, feel sick  2009-06-20  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['day'] = tweets['Date'].str.split().str[0]\n",
    "tweets['month'] = tweets['Date'].str.split().str[1]\n",
    "tweets['date'] = tweets['Date'].str.split().str[2]\n",
    "tweets['year'] = tweets['Date'].str.split().str[-1]\n",
    "\n",
    "tweets['date_time'] = tweets['day'] + ' ' + tweets['month'] + ' ' + tweets['date'] + ' ' + tweets['year']\n",
    "tweets['date_time'] = pd.to_datetime(tweets['date_time'], format='%a %b %d %Y')\n",
    "\n",
    "tweets.drop(columns=['day', 'month', 'date', 'year', 'Date'], inplace=True)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de671bf",
   "metadata": {},
   "source": [
    "### NLTK Text Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abf876",
   "metadata": {},
   "source": [
    "This demonstrates a text cleaning pipeline using NLTK (Natural Language Toolkit) in Python. It consists of a function clean_text() that preprocesses input text by removing special characters and digits, tokenizing the text, removing stopwords, and lemmatizing the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c567a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MILAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MILAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MILAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MILAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /kaggle/working/nltk_data/...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /kaggle/working/nltk_data/...\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nltk.download('wordnet', \"/kaggle/working/nltk_data/\")\n",
    "nltk.download('omw-1.4', \"/kaggle/working/nltk_data/\")\n",
    "! unzip /kaggle/working/nltk_data/corpora/wordnet.zip -d /kaggle/working/nltk_data/corpora\n",
    "! unzip /kaggle/working/nltk_data/corpora/omw-1.4.zip -d /kaggle/working/nltk_data/corpora\n",
    "nltk.data.path.append(\"/kaggle/working/nltk_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87a75d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9a28bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>poor little dumpling holmdel vids really tryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>im bed got ta wake hella early tomorrow morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>havent able listen yet speaker busted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>remembers solving relatively big equation two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>ate much feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \\\n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16   \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06   \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23   \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01   \n",
       "4                           Ate too much, feel sick  2009-06-20   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  poor little dumpling holmdel vids really tryin...  \n",
       "1    im bed got ta wake hella early tomorrow morning  \n",
       "2              havent able listen yet speaker busted  \n",
       "3  remembers solving relatively big equation two ...  \n",
       "4                                 ate much feel sick  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['cleaned_text'] = tweets['text']\n",
    "\n",
    "for i in range(len(tweets['cleaned_text'])):\n",
    "    str = tweets['cleaned_text'].iloc[i]\n",
    "    tweets.loc[i, 'cleaned_text'] = clean_text(str)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77361d7",
   "metadata": {},
   "source": [
    "### Sentiment Score Computation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0c0b49b",
   "metadata": {},
   "source": [
    "Sentiment Score Computation Loop: The function iterates over each entry in the specified column of the tweets DataFrame using a for loop. For each entry, it retrieves the text (t) from the specified column. It computes the sentiment scores for the text using the polarity_scores() method of the SentimentIntensityAnalyzer object (sia) and stores the scores in the respective arrays (neg, neu, pos, compound). This is done for both cleaned and uncleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3958b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_neg</th>\n",
       "      <th>text_neu</th>\n",
       "      <th>text_pos</th>\n",
       "      <th>text_compound</th>\n",
       "      <th>cleaned_text_neg</th>\n",
       "      <th>cleaned_text_neu</th>\n",
       "      <th>cleaned_text_pos</th>\n",
       "      <th>cleaned_text_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>poor little dumpling holmdel vids really tryin...</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.4013</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>im bed got ta wake hella early tomorrow morning</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>havent able listen yet speaker busted</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>remembers solving relatively big equation two ...</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>ate much feel sick</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \\\n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16   \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06   \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23   \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01   \n",
       "4                           Ate too much, feel sick  2009-06-20   \n",
       "\n",
       "                                        cleaned_text  text_neg  text_neu  \\\n",
       "0  poor little dumpling holmdel vids really tryin...     0.151     0.732   \n",
       "1    im bed got ta wake hella early tomorrow morning     0.000     1.000   \n",
       "2              havent able listen yet speaker busted     0.000     1.000   \n",
       "3  remembers solving relatively big equation two ...     0.168     0.711   \n",
       "4                                 ate much feel sick     0.452     0.548   \n",
       "\n",
       "   text_pos  text_compound  cleaned_text_neg  cleaned_text_neu  \\\n",
       "0     0.117        -0.4013             0.214             0.621   \n",
       "1     0.000         0.0000             0.000             1.000   \n",
       "2     0.000         0.0000             0.000             1.000   \n",
       "3     0.122        -0.2263             0.241             0.584   \n",
       "4     0.000        -0.5106             0.524             0.476   \n",
       "\n",
       "   cleaned_text_pos  cleaned_text_compound  \n",
       "0             0.166                -0.4013  \n",
       "1             0.000                 0.0000  \n",
       "2             0.000                 0.0000  \n",
       "3             0.175                -0.2263  \n",
       "4             0.000                -0.5106  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_scores(col):\n",
    "    \n",
    "    length = len(tweets[col])\n",
    "    neg = np.empty([1, length])\n",
    "    neg = neg[0]\n",
    "    neu = np.empty([1, length])\n",
    "    neu = neu[0]\n",
    "    pos = np.empty([1, length])\n",
    "    pos = pos[0]\n",
    "    compound = np.empty([1, length])\n",
    "    compound = compound[0]\n",
    "\n",
    "    for i in range(length):\n",
    "        t = tweets[col][i]\n",
    "        sentiment_scores = sia.polarity_scores(t)\n",
    "        neg[i] = sentiment_scores[\"neg\"]\n",
    "        neu[i] = sentiment_scores[\"neu\"]\n",
    "        pos[i] = sentiment_scores[\"pos\"]\n",
    "        compound[i] = sentiment_scores[\"compound\"]\n",
    "\n",
    "    tweets[col+\"_neg\"] = neg\n",
    "    tweets[col+\"_neu\"] = neu\n",
    "    tweets[col+\"_pos\"] = pos\n",
    "    tweets[col+\"_compound\"] = compound\n",
    "\n",
    "sent_scores(\"text\")\n",
    "sent_scores(\"cleaned_text\")\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9379d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in text_compound: -0.9776\n",
      "Maximum value in text_compound: 0.9928\n"
     ]
    }
   ],
   "source": [
    "min_value = tweets['text_compound'].min()\n",
    "max_value = tweets['text_compound'].max()\n",
    "\n",
    "print(\"Minimum value in text_compound:\", min_value)\n",
    "print(\"Maximum value in text_compound:\", max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858ba5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db4ce3",
   "metadata": {},
   "source": [
    "The compound score, a 'normalized, weighted composite score,' is derived by summing the valence scores of each word in the lexicon, adjusted based on specific rules, and then normalized to fall within the range of -1 (most extreme negative) to +1 (most extreme positive). This metric serves as a valuable single-dimensional measure of sentiment for a given sentence. Typical threshold values are as follows:\n",
    "\n",
    "* Positive sentiment: Compound score ≥ 0.05\n",
    "* Neutral sentiment: -0.05 < Compound score < 0.05\n",
    "* Negative sentiment: Compound score ≤ -0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0daffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= text_compound =============================\n",
      "ROC-AUC score: 0.7204268320995052\n",
      "Accuracy: 0.7191188040912667\n",
      "Recall: 0.8616529201961658\n",
      "============================= cleaned_text_compound =============================\n",
      "ROC-AUC score: 0.702428166876544\n",
      "Accuracy: 0.7025635893109907\n",
      "Recall: 0.8685962456070173\n"
     ]
    }
   ],
   "source": [
    "def evaluate(col):\n",
    "    \n",
    "    tweets['predicted_sentiment'] = tweets[col].apply(lambda x: 1 if x >= 0.05 else (0 if x <= -0.05 else None))\n",
    "    \n",
    "    # remove rows with neutral sentiment (nans)\n",
    "    tweets.dropna(subset=['predicted_sentiment'], inplace=True)\n",
    "\n",
    "    accuracy = accuracy_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    precision = precision_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    recall = recall_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    f1 = f1_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    roc_auc = roc_auc_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    \n",
    "    print(\"============================= \"+col+\" =============================\")\n",
    "    print(\"ROC-AUC score:\", roc_auc)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Recall:\", recall)\n",
    "    \n",
    "evaluate('text_compound')\n",
    "evaluate('cleaned_text_compound')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc8e4d71",
   "metadata": {},
   "source": [
    "While a ROC-AUC score of 0.7204 can serve as a reasonable starting point for sentiment analysis tasks, it's essential to consider various factors to determine its adequacy as a baseline. Additionally, continuous experimentation and refinement of models are often necessary to improve performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e3c53",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abd71771",
   "metadata": {},
   "source": [
    "Through this project, we have documented the observation that VADER performs better with uncleaned text data compared to cleaned text data. This notebook serves as a valuable resource for researchers, practitioners, and enthusiasts in the field of sentiment analysis, offering insights into the nuances of text preprocessing and its impact on sentiment analysis tool performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
